{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FlowPolicy on Kitchen Dataset - Google Colab\n",
        "\n",
        "Notebook lengkap: load data → training (CFM loss) → simulasi & evaluasi.\n",
        "\n",
        "**Sumber data (satu dari):**\n",
        "- **.npy**: file `all_observations.npy` dan `all_actions.npy` di `DATA_DIR`.\n",
        "- **.mjl**: file log MuJoCo (playdata) di `DATA_DIR` atau subfolder, mis. `kitchen_demos_multitask/friday_kettle_switch_hinge_slide/kitchen_playdata_*.mjl`. Jika .npy tidak ada, loader akan cari semua `.mjl` secara rekursif dan load otomatis.\n",
        "- **Sintetis**: jika keduanya tidak ada dan `USE_SYNTHETIC_IF_MISSING=True`.\n",
        "\n",
        "**Cara pakai di Colab:**\n",
        "1. Upload folder `kitchen` (berisi .npy dan/atau subfolder berisi .mjl) ke Colab, atau jalankan dengan data sintetis.\n",
        "2. Jika pakai Google Drive: mount Drive lalu set `DATA_DIR` ke path folder kitchen di Drive.\n",
        "3. Jalankan semua cell secara berurutan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Mount Google Drive (jika data kitchen ada di Drive)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# DATA_DIR = \"/content/drive/MyDrive/skripsi/kitchen\"  # sesuaikan path\n",
        "\n",
        "# Jika tidak mount Drive, pakai folder di Colab (upload manual) atau data sintetis\n",
        "DATA_DIR = \"/content/kitchen\"  # ganti jika upload ke path lain\n",
        "USE_MJL_IF_MISSING = True   # True = coba load dari file .mjl jika .npy tidak ada\n",
        "USE_SYNTHETIC_IF_MISSING = True  # True = pakai data sintetis jika .npy dan .mjl tidak ada\n",
        "\n",
        "!pip install -q tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Konfigurasi & Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Dimensi Kitchen (sesuaikan jika pakai dataset lain)\n",
        "STATE_DIM = 59\n",
        "ACTION_DIM = 9\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "NUM_EPOCHS = 50\n",
        "VAL_RATIO = 0.1\n",
        "\n",
        "# FlowPolicy\n",
        "HIDDEN_DIM = 512\n",
        "TIME_EMBED_DIM = 128\n",
        "NUM_INFERENCE_STEPS = 10\n",
        "CFM_EPS = 1e-2\n",
        "CFM_DELTA = 1e-2\n",
        "CFM_NUM_SEGMENTS = 2\n",
        "CFM_BOUNDARY = 1\n",
        "CFM_ALPHA = 1e-5\n",
        "\n",
        "SAVE_DIR = \"/content/checkpoints\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Kitchen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_kitchen_data(data_dir):\n",
        "    data = {}\n",
        "    for name in [\"all_observations\", \"all_actions\", \"observations_seq\", \"actions_seq\", \"existence_mask\"]:\n",
        "        path = os.path.join(data_dir, f\"{name}.npy\")\n",
        "        if os.path.isfile(path):\n",
        "            try:\n",
        "                arr = np.load(path, allow_pickle=True)\n",
        "                if hasattr(arr, 'shape') and len(arr.shape) > 0:\n",
        "                    data[name] = arr\n",
        "            except Exception as e:\n",
        "                print(f\"Skip {name}: {e}\")\n",
        "    return data\n",
        "\n",
        "def flatten_trajectories(obs, actions, mask=None):\n",
        "    if obs.ndim == 2:\n",
        "        return obs, actions\n",
        "    if mask is not None:\n",
        "        obs = obs[mask].reshape(-1, obs.shape[-1])\n",
        "        actions = actions[mask].reshape(-1, actions.shape[-1])\n",
        "    else:\n",
        "        obs = obs.reshape(-1, obs.shape[-1])\n",
        "        actions = actions.reshape(-1, actions.shape[-1])\n",
        "    return obs, actions\n",
        "\n",
        "def create_synthetic_kitchen(num_trajs=50, steps=100, obs_dim=59, action_dim=9, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    obs = rng.standard_normal((num_trajs, steps, obs_dim)).astype(np.float32)\n",
        "    actions = rng.standard_normal((num_trajs, steps, action_dim)).astype(np.float32)\n",
        "    return obs, actions\n",
        "\n",
        "class KitchenDataset(Dataset):\n",
        "    def __init__(self, obs, actions):\n",
        "        if obs.ndim == 3:\n",
        "            obs = obs.reshape(-1, obs.shape[-1])\n",
        "            actions = actions.reshape(-1, actions.shape[-1])\n",
        "        self.obs = torch.as_tensor(obs, dtype=torch.float32)\n",
        "        self.actions = torch.as_tensor(actions, dtype=torch.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.obs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.obs[idx], self.actions[idx]\n",
        "\n",
        "# Load data\n",
        "raw = load_kitchen_data(DATA_DIR)\n",
        "if raw and \"all_observations\" in raw and \"all_actions\" in raw:\n",
        "    obs = raw[\"all_observations\"]\n",
        "    actions = raw[\"all_actions\"]\n",
        "    mask = raw.get(\"existence_mask\")\n",
        "    obs, actions = flatten_trajectories(obs, actions, mask)\n",
        "    state_dim, action_dim = obs.shape[1], actions.shape[1]\n",
        "    print(f\"Loaded kitchen data (.npy): {obs.shape[0]} samples, state_dim={state_dim}, action_dim={action_dim}\")\n",
        "else:\n",
        "    obs, actions = None, None\n",
        "    if USE_MJL_IF_MISSING:\n",
        "        try:\n",
        "            from kitchen_dataset import load_kitchen_from_mjl, find_mjl_files\n",
        "            mjl_paths = find_mjl_files(DATA_DIR)\n",
        "            if mjl_paths:\n",
        "                obs, actions = load_kitchen_from_mjl(DATA_DIR, state_dim=STATE_DIM, action_dim=ACTION_DIM)\n",
        "                if obs is not None:\n",
        "                    state_dim, action_dim = obs.shape[1], actions.shape[1]\n",
        "                    print(f\"Loaded kitchen data (.mjl): {len(mjl_paths)} file(s), {obs.shape[0]} samples\")\n",
        "        except ImportError:\n",
        "            pass\n",
        "    if obs is None and USE_SYNTHETIC_IF_MISSING:\n",
        "        print(\"Data tidak ditemukan. Menggunakan data sintetis.\")\n",
        "        obs, actions = create_synthetic_kitchen(obs_dim=STATE_DIM, action_dim=ACTION_DIM)\n",
        "        obs = obs.reshape(-1, obs.shape[-1])\n",
        "        actions = actions.reshape(-1, actions.shape[-1])\n",
        "        state_dim, action_dim = STATE_DIM, ACTION_DIM\n",
        "    if obs is None:\n",
        "        raise FileNotFoundError(f\"Tidak ada data di {DATA_DIR}. Upload .npy/.mjl atau set USE_SYNTHETIC_IF_MISSING=True.\")\n",
        "\n",
        "dataset = KitchenDataset(obs, actions)\n",
        "n = len(dataset)\n",
        "n_val = max(1, int(n * VAL_RATIO))\n",
        "n_train = n - n_val\n",
        "train_ds, val_ds = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "print(f\"Train: {n_train}, Val: {n_val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Arsitektur FlowPolicy (Linear + ReLU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "class FlowPolicyVelocityNet(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=512, time_embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Sequential(\n",
        "            SinusoidalPosEmb(time_embed_dim),\n",
        "            nn.Linear(time_embed_dim, time_embed_dim * 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(time_embed_dim * 2, time_embed_dim),\n",
        "        )\n",
        "        input_dim = state_dim + action_dim + time_embed_dim\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim // 2, action_dim),\n",
        "        )\n",
        "    def forward(self, state, noisy_action, t):\n",
        "        t_emb = self.time_embed(t)\n",
        "        x = torch.cat([state, noisy_action, t_emb], dim=-1)\n",
        "        return self.net(x)\n",
        "\n",
        "class FlowPolicyModel(nn.Module):\n",
        "    def __init__(self, velocity_net, action_dim, num_inference_steps=10, eps=1e-2):\n",
        "        super().__init__()\n",
        "        self.velocity_net = velocity_net\n",
        "        self.action_dim = action_dim\n",
        "        self.num_inference_steps = num_inference_steps\n",
        "        self.eps = eps\n",
        "    def forward(self, state):\n",
        "        was_1d = state.dim() == 1\n",
        "        if was_1d:\n",
        "            state = state.unsqueeze(0)\n",
        "        B = state.shape[0]\n",
        "        device = state.device\n",
        "        z = torch.randn(B, self.action_dim, device=device)\n",
        "        dt = 1.0 / self.num_inference_steps\n",
        "        for i in range(self.num_inference_steps):\n",
        "            num_t = i / self.num_inference_steps * (1 - self.eps) + self.eps\n",
        "            t = torch.ones(B, device=device) * num_t\n",
        "            pred = self.velocity_net(state, z, t)\n",
        "            z = z + pred * dt\n",
        "        if was_1d:\n",
        "            z = z.squeeze(0)\n",
        "        return z\n",
        "\n",
        "def compute_cfm_loss(velocity_net, states, actions, device, eps=1e-2, delta=1e-2, num_segments=2, boundary=1, alpha=1e-5):\n",
        "    B = actions.shape[0]\n",
        "    a0 = torch.randn_like(actions)\n",
        "    t = torch.rand(B, device=device) * (1 - eps) + eps\n",
        "    r = torch.clamp(t + delta, max=1.0)\n",
        "    t_exp = t.unsqueeze(-1)\n",
        "    r_exp = r.unsqueeze(-1)\n",
        "    xt = t_exp * actions + (1 - t_exp) * a0\n",
        "    xr = r_exp * actions + (1 - r_exp) * a0\n",
        "    segments = torch.linspace(0, 1, num_segments + 1, device=device)\n",
        "    seg_idx = torch.searchsorted(segments, t, side=\"left\").clamp(min=1)\n",
        "    seg_ends = segments[seg_idx]\n",
        "    seg_ends_exp = seg_ends.unsqueeze(-1)\n",
        "    vt = velocity_net(states, xt, t)\n",
        "    vr = velocity_net(states, xr, r)\n",
        "    vr = torch.nan_to_num(vr)\n",
        "    ft = xt + (seg_ends_exp - t_exp) * vt\n",
        "    x_at_seg = seg_ends_exp * actions + (1 - seg_ends_exp) * a0\n",
        "    if boundary == 0:\n",
        "        fr = x_at_seg\n",
        "    else:\n",
        "        mask_b = t_exp < boundary\n",
        "        fr = mask_b * (xr + (seg_ends_exp - r_exp) * vr) + (~mask_b) * x_at_seg\n",
        "    losses_f = torch.mean((ft - fr) ** 2, dim=-1)\n",
        "    if boundary == 0:\n",
        "        losses_v = torch.zeros_like(losses_f)\n",
        "    else:\n",
        "        mask_b = (t < boundary).unsqueeze(-1)\n",
        "        mask_far = ((seg_ends - t) > 1.01 * delta).unsqueeze(-1)\n",
        "        losses_v = torch.mean(mask_b * mask_far * (vt - vr) ** 2, dim=-1)\n",
        "    return torch.mean(losses_f + alpha * losses_v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Inisialisasi Model & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "velocity_net = FlowPolicyVelocityNet(\n",
        "    state_dim=state_dim,\n",
        "    action_dim=action_dim,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    time_embed_dim=TIME_EMBED_DIM,\n",
        ").to(device)\n",
        "\n",
        "flowpolicy_model = FlowPolicyModel(\n",
        "    velocity_net=velocity_net,\n",
        "    action_dim=action_dim,\n",
        "    num_inference_steps=NUM_INFERENCE_STEPS,\n",
        "    eps=CFM_EPS,\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in velocity_net.parameters())\n",
        "print(f\"FlowPolicy - Total parameters: {total_params:,}\")\n",
        "\n",
        "optimizer = Adam(velocity_net.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    velocity_net.train()\n",
        "    epoch_train_losses = []\n",
        "    for states, actions in tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} [Train]\", leave=False):\n",
        "        states = states.to(device)\n",
        "        actions = actions.to(device)\n",
        "        loss = compute_cfm_loss(\n",
        "            velocity_net, states, actions, device,\n",
        "            eps=CFM_EPS, delta=CFM_DELTA,\n",
        "            num_segments=CFM_NUM_SEGMENTS, boundary=CFM_BOUNDARY, alpha=CFM_ALPHA,\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_losses.append(loss.item())\n",
        "\n",
        "    velocity_net.eval()\n",
        "    epoch_val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for states, actions in tqdm(val_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} [Val]\", leave=False):\n",
        "            states = states.to(device)\n",
        "            actions = actions.to(device)\n",
        "            loss = compute_cfm_loss(\n",
        "                velocity_net, states, actions, device,\n",
        "                eps=CFM_EPS, delta=CFM_DELTA,\n",
        "                num_segments=CFM_NUM_SEGMENTS, boundary=CFM_BOUNDARY, alpha=CFM_ALPHA,\n",
        "            )\n",
        "            epoch_val_losses.append(loss.item())\n",
        "\n",
        "    avg_train = np.mean(epoch_train_losses)\n",
        "    avg_val = np.mean(epoch_val_losses)\n",
        "    train_loss_history.append(avg_train)\n",
        "    val_loss_history.append(avg_val)\n",
        "\n",
        "    if avg_val < best_val_loss:\n",
        "        best_val_loss = avg_val\n",
        "        torch.save({\n",
        "            \"velocity_net_state_dict\": velocity_net.state_dict(),\n",
        "            \"state_dim\": state_dim,\n",
        "            \"action_dim\": action_dim,\n",
        "            \"hidden_dim\": HIDDEN_DIM,\n",
        "            \"time_embed_dim\": TIME_EMBED_DIM,\n",
        "            \"num_inference_steps\": NUM_INFERENCE_STEPS,\n",
        "            \"cfm_eps\": CFM_EPS,\n",
        "        }, os.path.join(SAVE_DIR, \"flow_policy_best.pt\"))\n",
        "        print(f\"  -> Model saved (val_loss={avg_val:.6f})\")\n",
        "\n",
        "    print(f\"EPOCH {epoch}/{NUM_EPOCHS} - Train Loss: {avg_train:.6f}, Val Loss: {avg_val:.6f}\")\n",
        "\n",
        "print(f\"\\nTraining selesai. Best val_loss = {best_val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Plot Kurva Training & Simpan Metrik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_history, label=\"Train Loss\")\n",
        "plt.plot(val_loss_history, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Consistency Flow Matching Loss\")\n",
        "plt.title(\"FlowPolicy Training Curves - Kitchen\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(SAVE_DIR, \"flowpolicy_training_curves.png\"), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "with open(os.path.join(SAVE_DIR, \"train_metrics.json\"), \"w\") as f:\n",
        "    json.dump({\"train_loss\": train_loss_history, \"val_loss\": val_loss_history}, f, indent=2)\n",
        "print(\"Metrik training disimpan ke train_metrics.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Simulasi & Evaluasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model terbaik\n",
        "ckpt = torch.load(os.path.join(SAVE_DIR, \"flow_policy_best.pt\"), map_location=device)\n",
        "velocity_net.load_state_dict(ckpt[\"velocity_net_state_dict\"])\n",
        "flowpolicy_model.eval()\n",
        "\n",
        "# Evaluasi pada seluruh dataset (atau subset)\n",
        "all_obs = dataset.obs\n",
        "all_actions = dataset.actions\n",
        "max_eval = min(5000, len(all_obs))  # batas sampel evaluasi\n",
        "obs_eval = all_obs[:max_eval].to(device)\n",
        "targets = all_actions[:max_eval]\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = flowpolicy_model(obs_eval).cpu().numpy()\n",
        "targets_np = targets.numpy()\n",
        "\n",
        "mse = np.mean((preds - targets_np) ** 2)\n",
        "mae = np.mean(np.abs(preds - targets_np))\n",
        "ss_tot = np.sum((targets_np - targets_np.mean(axis=0)) ** 2)\n",
        "ss_res = np.sum((targets_np - preds) ** 2)\n",
        "r2 = float(1 - ss_res / (ss_tot + 1e-12))\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"  SIMULASI & EVALUASI - FlowPolicy on Kitchen\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  MSE:  {mse:.6f}\")\n",
        "print(f\"  MAE:  {mae:.6f}\")\n",
        "print(f\"  R²:   {r2:.6f}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Simpan Hasil Evaluasi & Download (opsional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RESULTS_DIR = \"/content/evaluation_results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(RESULTS_DIR, \"flow_policy_metrics.txt\"), \"w\") as f:\n",
        "    f.write(\"FlowPolicy on Kitchen - Simulation & Evaluation\\n\")\n",
        "    f.write(\"=\" * 60 + \"\\n\")\n",
        "    f.write(f\"MSE:  {mse:.6f}\\n\")\n",
        "    f.write(f\"MAE:  {mae:.6f}\\n\")\n",
        "    f.write(f\"R²:   {r2:.6f}\\n\")\n",
        "\n",
        "np.savez(\n",
        "    os.path.join(RESULTS_DIR, \"flow_policy_predictions.npz\"),\n",
        "    predictions=preds,\n",
        "    targets=targets_np,\n",
        ")\n",
        "\n",
        "print(\"Metrik dan prediksi disimpan di\", RESULTS_DIR)\n",
        "\n",
        "# Download dari Colab (uncomment jika perlu)\n",
        "# from google.colab import files\n",
        "# files.download(os.path.join(SAVE_DIR, \"flow_policy_best.pt\"))\n",
        "# files.download(os.path.join(SAVE_DIR, \"flowpolicy_training_curves.png\"))\n",
        "# files.download(os.path.join(RESULTS_DIR, \"flow_policy_metrics.txt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Video Hasil Pengujian (max 280 timesteps) & Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rekam video rollout FlowPolicy dengan max 280 timestep\n",
        "MAX_VIDEO_TIMESTEPS = 280\n",
        "VIDEO_FPS = 10\n",
        "video_path = os.path.join(RESULTS_DIR, f\"flowpolicy_rollout_{MAX_VIDEO_TIMESTEPS}.mp4\")\n",
        "\n",
        "try:\n",
        "    from simulate_and_evaluate import record_rollout_video\n",
        "    video_path = record_rollout_video(flowpolicy_model, dataset, device, video_path, max_timesteps=MAX_VIDEO_TIMESTEPS, fps=VIDEO_FPS) or video_path\n",
        "except ImportError:\n",
        "    import matplotlib\n",
        "    matplotlib.use(\"Agg\")\n",
        "    import matplotlib.pyplot as plt\n",
        "    flowpolicy_model.eval()\n",
        "    obs_v = dataset.obs[:MAX_VIDEO_TIMESTEPS]\n",
        "    acts_gt = dataset.actions[:MAX_VIDEO_TIMESTEPS]\n",
        "    with torch.no_grad():\n",
        "        preds_v = flowpolicy_model(obs_v.to(device)).cpu().numpy()\n",
        "    obs_v = obs_v.numpy()\n",
        "    acts_gt = acts_gt.numpy()\n",
        "    T = len(obs_v)\n",
        "    frames = []\n",
        "    for t in range(T):\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 5))\n",
        "        fig.suptitle(f\"FlowPolicy Rollout — timestep {t+1}/{T}\")\n",
        "        ax1.bar(range(min(8, obs_v.shape[1])), obs_v[t, :8], color=\"steelblue\", alpha=0.8)\n",
        "        ax1.set_ylabel(\"state (subset)\")\n",
        "        x = np.arange(min(9, preds_v.shape[1]))\n",
        "        ax2.bar(x - 0.18, preds_v[t, :len(x)], 0.35, label=\"pred\", color=\"green\", alpha=0.8)\n",
        "        ax2.bar(x + 0.18, acts_gt[t, :len(x)], 0.35, label=\"target\", color=\"orange\", alpha=0.8)\n",
        "        ax2.set_ylabel(\"action\")\n",
        "        ax2.legend()\n",
        "        plt.tight_layout()\n",
        "        fig.canvas.draw()\n",
        "        img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "        frames.append(img)\n",
        "        plt.close(fig)\n",
        "    import imageio\n",
        "    imageio.mimsave(video_path.replace(\".mp4\", \".gif\"), frames, fps=VIDEO_FPS, loop=0)\n",
        "    video_path = video_path.replace(\".mp4\", \".gif\")\n",
        "    print(f\"Video disimpan: {video_path}\")\n",
        "\n",
        "# Download video (di Colab akan trigger download ke komputer)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(video_path)\n",
        "    print(\"Download video berhasil.\")\n",
        "except ImportError:\n",
        "    print(f\"Untuk download manual, ambil file: {os.path.abspath(video_path)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
